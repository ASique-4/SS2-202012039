# PROYECTO 2

| Nombre                       | Carnet    |
| ---------------------------- | --------- |
| Angel Francisco Sique Santos | 202012039 |

---

# ndice

1. [Introducci贸n](#introducci贸n)
2. [Proceso de ETL](#proceso-de-etl)
   - [1. Extracci贸n de Datos](#1-extracci贸n-de-datos)
     - [1.1 Cargar datos locales (`municipio.csv`)](#11-cargar-datos-locales-municipiocsv)
     - [1.2 Descargar y cargar datos globales desde Google Drive](#12-descargar-y-cargar-datos-globales-desde-google-drive)
   - [2. Transformaci贸n de Datos](#2-transformaci贸n-de-datos)
     - [2.1 Limpieza del archivo local (`municipio.csv`)](#21-limpieza-del-archivo-local-municipiocsv)
       - [Conversi贸n de columnas num茅ricas](#conversi贸n-de-columnas-num茅ricas)
       - [Validaci贸n de columnas de texto](#validaci贸n-de-columnas-de-texto)
       - [Transformar fechas din谩micas en filas](#transformar-fechas-din谩micas-en-filas)
       - [Formateo y validaci贸n de fechas](#formateo-y-validaci贸n-de-fechas)
     - [2.2 Limpieza del archivo remoto (`global_calificacion.csv`)](#22-limpieza-del-archivo-remoto-global_calificacioncsv)
       - [Filtrar datos de Guatemala](#filtrar-datos-de-guatemala)
       - [Formateo de fechas y eliminaci贸n de valores no v谩lidos](#formateo-de-fechas-y-eliminaci贸n-de-valores-no-v谩lidos)
       - [Filtrar por el a帽o 2020](#filtrar-por-el-a帽o-2020)
       - [Eliminar duplicados](#eliminar-duplicados)
     - [2.3 Combinaci贸n de datos](#23-combinaci贸n-de-datos)
   - [3. Preparaci贸n de Tablas para SQL](#3-preparaci贸n-de-tablas-para-sql)
     - [Tabla `Departamento`](#tabla-departamento)
     - [Tabla `Municipio`](#tabla-municipio)
     - [Tabla `DatosCovid`](#tabla-datoscovid)
   - [4. Carga a la Base de Datos](#4-carga-a-la-base-de-datos)

---

### **Introducci贸n**

Este proyecto implementa un proceso de ETL (*Extract, Transform, Load*) para procesar datos relacionados con casos de COVID-19. Los datos combinan informaci贸n local de municipios y datos globales de la pandemia.

---

### **Proceso de ETL**

## **1. Extracci贸n de Datos**

### **1.1 Cargar datos locales (`municipio.csv`)**
```python
dfLocal = pd.read_csv('municipio.csv')
```
- **Descripci贸n**: Carga un archivo CSV que contiene informaci贸n de los municipios de Guatemala. Este archivo tiene columnas como:
  - `departamento`: Nombre del departamento.
  - `codigo_departamento`: C贸digo 煤nico del departamento.
  - `municipio`: Nombre del municipio.
  - `codigo_municipio`: C贸digo 煤nico del municipio.
  - `poblacion`: Poblaci贸n del municipio.
  - Fechas: Datos de casos confirmados registrados por fechas espec铆ficas.

---

### **1.2 Descargar y cargar datos globales desde Google Drive**
```python
file_id = "1vzZ24iSQ7LZM9Rc3oSuIQmqzKp5-YFNO"
url = f"https://drive.google.com/uc?id={file_id}"
dfRemoto = pd.read_csv(url)
```
- **Descripci贸n**: Se descarga program谩ticamente un archivo CSV desde Google Drive utilizando su ID. El archivo contiene datos globales de casos y muertes por COVID-19.
- **Campos importantes**:
  - `Date_reported`: Fecha de reporte.
  - `Country`: Pa铆s.
  - `Country_code`: C贸digo ISO del pa铆s.
  - `New_cases`: Nuevos casos confirmados en la fecha.
  - `New_deaths`: Nuevas muertes confirmadas en la fecha.

---

## **2. Transformaci贸n de Datos**

### **2.1 Limpieza del archivo local (`municipio.csv`)**

#### **Conversi贸n de columnas num茅ricas**
```python
for col in ['codigo_departamento', 'codigo_municipio', 'poblacion']:
    dfLocal[col] = pd.to_numeric(dfLocal[col], errors='coerce').fillna(0).astype(int)
```
- **Objetivo**: Convertir columnas clave a enteros, manejando errores y valores nulos.
- **Explicaci贸n**:
  - `pd.to_numeric`: Convierte los datos a formato num茅rico.
  - `errors='coerce'`: Los valores no v谩lidos se convierten en `NaN`.
  - `fillna(0)`: Sustituye los valores nulos por 0.
  - `astype(int)`: Convierte los valores finales a enteros.

#### **Validaci贸n de columnas de texto**
```python
for col in ['departamento', 'municipio']:
    dfLocal = dfLocal[dfLocal[col].str.match(r'^[a-zA-Z\s]+$', na=False)]
```
- **Objetivo**: Validar que las columnas de texto contengan 煤nicamente letras y espacios.
- **Explicaci贸n**:
  - `str.match`: Aplica una expresi贸n regular para verificar el formato del texto.
  - `^[a-zA-Z\s]+$`: Permite 煤nicamente letras y espacios.

#### **Transformar fechas din谩micas en filas**
```python
dfLocal = dfLocal.melt(
    id_vars=['departamento', 'codigo_departamento', 'municipio', 'codigo_municipio', 'poblacion'],
    var_name='fecha',
    value_name='casos_confirmados'
)
```
- **Objetivo**: Convertir columnas de fechas en filas para estructurar mejor los datos.
- **Explicaci贸n**:
  - `id_vars`: Mantiene las columnas fijas (que no se transforman).
  - `var_name`: Define el nombre de la columna que contendr谩 las fechas.
  - `value_name`: Define el nombre de la columna con los valores de casos confirmados.

#### **Formateo y validaci贸n de fechas**
```python
dfLocal['fecha'] = pd.to_datetime(dfLocal['fecha'], format='%m/%d/%Y', errors='coerce')
dfLocal = dfLocal.dropna(subset=['fecha'])
```
- **Objetivo**: Convertir la columna `fecha` al formato `datetime` y eliminar valores no v谩lidos.
- **Explicaci贸n**:
  - `pd.to_datetime`: Convierte las fechas al formato est谩ndar `datetime`.
  - `errors='coerce'`: Los valores no v谩lidos se convierten en `NaT` (Not a Time).
  - `dropna`: Elimina filas donde la fecha es inv谩lida.

---

### **2.2 Limpieza del archivo remoto (`global_calificacion.csv`)**

#### **Filtrar datos de Guatemala**
```python
dfRemoto = dfRemoto[
    (dfRemoto['Country'].str.lower() == 'guatemala') | (dfRemoto['Country_code'] == 'GT')
]
```
- **Objetivo**: Seleccionar 煤nicamente los datos correspondientes a Guatemala.
- **Explicaci贸n**:
  - Filtra las filas donde `Country` sea "Guatemala" o `Country_code` sea "GT".

#### **Formateo de fechas y eliminaci贸n de valores no v谩lidos**
```python
dfRemoto['Date_reported'] = pd.to_datetime(dfRemoto['Date_reported'], format='%m/%d/%Y', errors='coerce')
dfRemoto.dropna(subset=['Date_reported'], inplace=True)
```
- **Objetivo**: Convertir `Date_reported` a formato `datetime` y eliminar valores nulos.

#### **Filtrar por el a帽o 2020**
```python
dfRemoto = dfRemoto[dfRemoto['Date_reported'].dt.year == 2020]
```
- **Objetivo**: Seleccionar 煤nicamente los datos del a帽o 2020.

#### **Eliminar duplicados**
```python
dfRemoto = dfRemoto.drop_duplicates()
```
- **Objetivo**: Eliminar filas duplicadas.

---

### **2.3 Combinaci贸n de datos**
```python
dfCombinado = pd.merge(
    dfLocal,
    dfRemoto,
    how='inner',
    left_on='fecha',
    right_on='Date_reported'
)
```
- **Objetivo**: Combinar ambos datasets por la columna de fechas.
- **Explicaci贸n**:
  - `left_on`: Columna de fechas en `dfLocal`.
  - `right_on`: Columna de fechas en `dfRemoto`.
  - `how='inner'`: Combina 煤nicamente las filas que coinciden en ambos DataFrames.

---

### **3. Preparaci贸n de Tablas para SQL**

#### **Tabla `Departamento`**
```python
dfDepartamento = dfCombinado[['codigo_departamento', 'departamento']].drop_duplicates()
```

#### **Tabla `Municipio`**
```python
dfMunicipio = dfCombinado[['codigo_municipio', 'municipio', 'codigo_departamento', 'poblacion']].drop_duplicates()
```

#### **Tabla `DatosCovid`**
```python
dfDatosCovid = dfCombinado[['codigo_municipio', 'fecha', 'casos_confirmados', 'New_cases', 'Cumulative_cases', 'New_deaths', 'Cumulative_deaths']]
dfDatosCovid.rename(columns={
    'New_cases': 'casos_nuevos',
    'New_deaths': 'muertes',
    'Cumulative_cases': 'casos_acumulativos',
    'Cumulative_deaths': 'muertes_acumulativas'
}, inplace=True)
```

---

### **4. Carga a la Base de Datos**
```python
conexion = con.conectar_bd("practica1.db")
con.insertar_departamento(conexion, dfDepartamento)
con.insertar_municipio(conexion, dfMunicipio)
con.insertar_datos_covid(conexion, dfDatosCovid)
```
- **Objetivo**: Insertar los datos procesados en las tablas SQL:
  - **`Departamento`**: Contiene los datos de departamentos.
  - **`Municipio`**: Contiene los datos de municipios.
  - **`DatosCovid`**: Contiene los datos de COVID-19.

---

Con esta documentaci贸n detallada, cada paso del c贸digo queda claramente explicado, desde la extracci贸n de datos hasta la carga en SQL. 驴Hay alg煤n punto que necesites ajustar o expandir? 